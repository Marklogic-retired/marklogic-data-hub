plugins {
    id "java-library"
    id 'com.github.johnrengelman.shadow' version '5.2.0'

    id "io.snyk.gradle.plugin.snykplugin" version "0.4"
}

group = 'com.marklogic'

// See https://github.com/snyk/gradle-plugin for docs
snyk {
    severity = 'medium'
    api = snykToken
    autoDownload = true
    autoUpdate = true
}

configurations {
    // Some of the Spark dependencies bring in junit 3, which we don't want on the classpath
    all*.exclude group: "junit", module: "junit"
}

dependencies {
    api(project(":marklogic-data-hub-api"))

    // Makes it possible to use lambdas in Java 8 to implement Spark's Function1 and Function2 interfaces
    // See https://github.com/scala/scala-java8-compat for more information
    api ("org.scala-lang.modules:scala-java8-compat_2.11:0.9.1") {
        exclude module: "scala-library"
    }

    // We need to compile against the Spark jars, but we don't want to include them in the shadowJar
    compileOnly "org.apache.spark:spark-sql_2.11:${sparkVersion}"
    compileOnly "org.apache.spark:spark-launcher_2.11:${sparkVersion}"
    compileOnly "org.apache.spark:spark-catalyst_2.11:${sparkVersion}"
    compileOnly "org.apache.spark:spark-streaming_2.11:${sparkVersion}"
    compileOnly "org.apache.spark:spark-core_2.11:${sparkVersion}"

    // Depends on the test plumbing classes in the test project
    testImplementation(project(":marklogic-data-hub-test"))

    testImplementation "org.junit.jupiter:junit-jupiter:5.7.2"

    // Need to declare the Spark dependencies here too so they're available for tests
    testImplementation "org.apache.spark:spark-sql_2.11:${sparkVersion}"
    testImplementation "org.apache.spark:spark-launcher_2.11:${sparkVersion}"
    testImplementation "org.apache.spark:spark-catalyst_2.11:${sparkVersion}"
    testImplementation "org.apache.spark:spark-streaming_2.11:${sparkVersion}"
    testImplementation "org.apache.spark:spark-core_2.11:${sparkVersion}"
}

tasks.withType(Test) {
    systemProperty "mlHost", mlHost
    systemProperty "isDhs", isDhs
    useJUnitPlatform()
}

task copyModulesForConnectorFromCoreProject(type: Copy) {
    description = "Copy modules that the connector may need to install from the core project to the resources " +
        "directory so that they are included when the shadowJar is created"
    from "../marklogic-data-hub/src/main/resources/ml-modules/root"
    into "src/main/resources"
    include "marklogic-data-hub-spark-connector/**"
}

// Gradle's processResources task provides a chance for including additional files in the jar
// See https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_source_sets for more information
processResources.dependsOn copyModulesForConnectorFromCoreProject

shadowJar {
    classifier "needs-to-be-fixed"
    // Relocate packages of classes that the ML Java Client needs; it can't use the versions provided by Spark
    relocate('okio', 'marklogic.okio')

    relocate('com.fasterxml.jackson', 'marklogic.com.fasterxml.jackson')
}


//The relocated JsonRowParser class is being replaced with the original version so that it still uses the Spark version
// of Jackson as opposed to the ML version of Jackson.
task fixShadowJar(type: Jar, dependsOn: "shadowJar") {
    classifier "all"
    from (zipTree(shadowJar.archiveFile)) {
        exclude "com/marklogic/hub/spark/sql/sources/v2/reader/JsonRowParser.class"
    }
    from ("build/classes/java/main/") {
        include "com/marklogic/hub/spark/sql/sources/v2/reader/JsonRowParser.class"
    }
}
task copyConnectorToSparkTestProject(type: Copy) {
    description = "Build and copy the connector shadowJar to a gitignored directory in spark-test-project"
    from "build/libs"
    into "spark-test-project/lib"
    include "*-all.jar"
}
copyConnectorToSparkTestProject.dependsOn fixShadowJar

build.dependsOn fixShadowJar
