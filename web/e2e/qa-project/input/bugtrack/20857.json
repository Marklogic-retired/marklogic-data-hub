{"id":20857, "kind":"Bug", "createdAt":"2013-02-20T16:06:02.821023-08:00", "status":"Closed", "title":"XDMP-TOOMANYSTANDS when a forest is restarted too frequently", "category":"Replication", "severity":"Minor", "priority":{"level":"5", "title":""}, "submittedBy":{"username":"svempati", "name":"Sundeep Vempati", "email":"sundeep.vempati@marklogic.com"}, "assignTo":{"username":"nobody", "name":"nobody nobody", "email":"nobody@marklogic.com"}, "description":"Local Disk + DB Rep with flash backups : Forests getting into error state and documents missing at the end of stress test\r\n\r\nI started DB Rep + Local Disk Failover stress test to verify this bug:\r\nBug 20601 -  Replica forest stays in \"Finish Closing\" for 3 minutes before going back to \"Open Replica\" state, when moved from flash-backup to all\r\n\r\nMachines used:\r\nMaster Cluster:\r\nrh5-amd64-failover-1 [E-Node]\r\nrh5-intel64-21 [D-Node]\r\nrh5-intel64-22 [D-Node]\r\n  \r\nReplica Cluster:\r\nrh5-amd64-failover-2 [E-Node]\r\nrh5-intel64-23 [D-Node]\r\nrh5-intel64-24 [D-Node] \r\n\r\nModified cronjobs to take \"Modules\", \"Triggers\" and \"MedlineDB\" databases into flash backup mode and out every 20 minutes on Master and replica (sleep 25 seconds after taking forests into flash backup mode before taking them back into updates allowed=all)\r\n\r\nCronjob on Master E-node:\r\n0,20,40 * * * * /home/builder/flash_backup.sh\r\n\r\nCronjob on Replica E-node:\r\n10,30,50 * * * * /home/builder/flash_backup.sh\r\n\r\n\r\nI am seeing following Error on one of the forests in Master Cluster:\r\nXDMP-FORESTERR: Error in startup of forest F1B-R: XDMP-RECOVERY: Recovery error on forest F1B-R after 1 redo records -- {{fsn=9875157, chksum=0x98058e30, words=2469}, op=insert, time=1361398836, mfor=7770072018240975050, mtim=13613442063879610, mfsn=9874702, fmcl=15575198503299167945, fmf=7770072018240975050, fmfsn=9874702, sk=3970617330858001244} XDMP-TOOMANYSTANDS: Too many stands\r\n\r\nAnd the following Error on one of the forests in Replica cluster:\r\nXDMP-FORESTERR: Error in startup of forest F1A-R: XDMP-RECOVERY: Recovery error on forest F1A-R after 0 redo records -- {{fsn=8178825, chksum=0x9bc948a0, words=3064}, op=replicateFragment, time=1361399540, mfor=0, mtim=0, mfsn=0, fmcl=0, fmf=0, fmfsn=0, sk=3253209527467517604} XDMP-TOOMANYSTANDS: Too many stands\r\n\r\nI will attach the scripts I used to take the forests into flash-backup mode and out and also attach ErrorLogs from all the hosts.\r\n\r\n", "samplequery":"", "sampledata":"", "version":"5.0-1", "tofixin":"5.0-6", "fixedin":"5.0-6", "platform":"all", "memory":"", "processors":"", "note":"", "subscribers":[{"username":"svempati", "name":"Sundeep Vempati", "email":"sundeep.vempati@marklogic.com"}, {"username":"atsoi", "name":"Arthur Tsoi", "email":"arthur.tsoi@marklogic.com"}, {"username":"wfeick", "name":"Wayne Feick", "email":"wfeick@marklogic.com"}, {"username":"cjl", "name":"Christopher Lindblad", "email":"cjl@cerisent.com"}], "attachments":[{"name":"Shell script used in cron job", "uri":"root/support/bugtracking/attachments/20857/flash_backup.sh"}, {"name":"xquery module under qa appserver root", "uri":"root/support/bugtracking/attachments/20857/flash_backup.xqy"}, {"name":"second module under qa appserver root", "uri":"root/support/bugtracking/attachments/20857/updates_all.xqy"}, {"name":"ErrorLogs from all hosts on Master Cluster", "uri":"root/support/bugtracking/attachments/20857/masterlogs-022013-155732.tar.gz"}, {"name":"ErrorLogs from all hosts on Replica Cluster", "uri":"root/support/bugtracking/attachments/20857/replicalogs-022013-155821.tar.gz"}], "relationships":[{"type":"", "to":""}], "clones":[20862, 20863], "cloneOf":"", "support":{"headline":"", "supportDescription":"", "publishStatus":"Never Publish", "tickets":[], "customerImpact":{"level":"N/A", "title":""}, "workaround":""}, "tags":["Replication", "svempati"], "changeHistory":[{"time":"2013-02-20T16:06:02.821023-08:00", "updatedBy":{"username":"svempati", "name":"Sundeep Vempati", "email":"sundeep.vempati@marklogic.com"}, "change":{"assignTo":{"from":{"username":"svempati", "name":"Sundeep Vempati", "email":"sundeep.vempati@marklogic.com"}, "to":{"username":"wfeick", "name":"Wayne Feick", "email":"wfeick@marklogic.com"}}}, "files":[], "show":true}, {"time":"2013-02-20T16:18:44.011808-08:00", "updatedBy":{"username":"svempati", "name":"Sundeep Vempati", "email":"sundeep.vempati@marklogic.com"}, "change":{}, "files":[], "show":true, "comment":"Steps:\r\n1. Setup Local disk Failover on Master and Replica.\r\n2. Have modules to be used by shred.sh under Modules database.\r\n3. Change FailoverTest appserver setting pointing modules to \"Modules\" database\r\n4. Change qa appserver setting to use \"basic\" as authentication method.\r\n5. change bootstrap hosts on both clusters to the ones on which Security-M and Security-R reside.\r\n6. couple clusters and enable database replication between MedlineDB.\r\n7. Copy attached xqy modules into qa appserver's root.\r\n8. start medline.sh on master cluster.\r\n9. setup cronjobs on Master and Replica with flash_backup.sh script (attached).\r\n\r\nAfter loading about 10 million documents I see that forests are getting into Error state. \r\n\r\nLast night I saw the forests go into Error state much quicker if I have more number of forests (16 per host)."}, {"time":"2013-02-20T17:29:49.232429-08:00", "updatedBy":{"username":"wfeick", "name":"Wayne Feick", "email":"wfeick@marklogic.com"}, "change":{}, "files":[], "show":true, "comment":"I spoke with Sundeep about this. He's transitioning to flash backup mode every 20 minutes, which worked for a while until a 20G merge needed to happen that could not finish in the 20 minutes. After that point in time, we started accumulating stands but never merging any and eventually we had too many stands.\r\n\r\nI'm pushing this out to 5.0-6 because it's a contrived case that I wouldn't expect a user to hit in the real world.\r\n\r\nI think a sufficient fix might be to not throw XDMP-TOOMANYSTANDS if the forest is recovering. This would allow the forest to at least get back to an open state at which time I think it would start rejecting new update transactions until a merge is able to successfully complete."}, {"time":"2013-02-20T17:29:49.232429-08:00", "updatedBy":{"username":"wfeick", "name":"Wayne Feick", "email":"wfeick@marklogic.com"}, "change":{"tofixin":{"from":"5.0-5", "to":"5.0-6"}}, "files":[], "show":true}, {"time":"2013-02-20T17:32:06.009843-08:00", "updatedBy":{"username":"wfeick", "name":"Wayne Feick", "email":"wfeick@marklogic.com"}, "change":{"status":{"from":"", "to":"Fix"}, "assignTo":{"from":{"username":"wfeick", "name":"Wayne Feick", "email":"wfeick@marklogic.com"}, "to":{"username":"wfeick", "name":"Wayne Feick", "email":"wfeick@marklogic.com"}}}, "files":[], "show":true}, {"time":"2013-02-20T17:42:55.300261-08:00", "updatedBy":{"username":"dsokolsky", "name":"Danny Sokolsky", "email":"dsokolsky@marklogic.com"}, "change":{}, "files":[], "show":true, "comment":"So if one gets in this state, how does one revover?  Will putting the forest in updates-allowed state allow the forest to mount and then merge?"}, {"time":"2013-02-20T17:48:06.176902-08:00", "updatedBy":{"username":"wfeick", "name":"Wayne Feick", "email":"wfeick@marklogic.com"}, "change":{}, "files":[], "show":true, "comment":"You can't reasonably recover. Perhaps moving some stands out of the forest and restarting it, waiting for a merge to complete, moving them back in, restarting, ..."}, {"time":"2013-02-20T18:29:42.008759-08:00", "updatedBy":{"username":"dsokolsky", "name":"Danny Sokolsky", "email":"dsokolsky@marklogic.com"}, "change":{}, "files":[], "show":true, "comment":"What seems wierd here is that we ever got into the state with XDMP-TOOMANYSTANDS--I thought that a transaction would fail to commit (with TOOMANYSTANDS) if it left the forest with too many stands.  Apparently not...."}, {"time":"2013-05-21T13:15:41.069427-07:00", "updatedBy":{"username":"wfeick", "name":"Wayne Feick", "email":"wfeick@marklogic.com"}, "change":{"assignTo":{"from":{"username":"wfeick", "name":"Wayne Feick", "email":"wfeick@marklogic.com"}, "to":{"username":"atsoi", "name":"Arthur Tsoi", "email":"arthur.tsoi@marklogic.com"}}}, "files":[], "show":true}, {"time":"2013-06-19T10:16:42.144037-07:00", "updatedBy":{"username":"cjl", "name":"Christopher Lindblad", "email":"cjl@cerisent.com"}, "change":{}, "files":[], "show":true, "comment":"I don't think we should do anything to fix this."}, {"time":"2013-06-20T12:41:15.429035-07:00", "updatedBy":{"username":"cjl", "name":"Christopher Lindblad", "email":"cjl@cerisent.com"}, "change":{"assignTo":{"from":{"username":"cjl", "name":"Christopher Lindblad", "email":"cjl@cerisent.com"}, "to":{"username":"cjl", "name":"Christopher Lindblad", "email":"cjl@cerisent.com"}}}, "files":[], "show":true}, {"time":"2013-06-20T13:39:01.94261-07:00", "updatedBy":{"username":"cjl", "name":"Christopher Lindblad", "email":"cjl@cerisent.com"}, "change":{"status":{"from":"", "to":"Test"}, "assignTo":{"from":{"username":"cjl", "name":"Christopher Lindblad", "email":"cjl@cerisent.com"}, "to":{"username":"svempati", "name":"Sundeep Vempati", "email":"sundeep.vempati@marklogic.com"}}}, "files":[], "show":true, "comment":"fixed in 5.0-20130621\r\nnow during recovery:\r\nthe stand limit is double the normal value\r\nthere is no insert throttle so recovery should finish faster\r\nmerges are limited to 4GB so they should finish faster"}, {"time":"2013-06-20T13:39:01.94261-07:00", "updatedBy":{"username":"cjl", "name":"Christopher Lindblad", "email":"cjl@cerisent.com"}, "change":{"assignTo":{"from":{"username":"cjl", "name":"Christopher Lindblad", "email":"cjl@cerisent.com"}, "to":{"username":"svempati", "name":"Sundeep Vempati", "email":"sundeep.vempati@marklogic.com"}}}, "files":[], "show":true}, {"time":"2013-06-20T21:39:03.882965-07:00", "updatedBy":{"username":"cjl", "name":"Christopher Lindblad", "email":"cjl@cerisent.com"}, "change":{}, "files":[], "show":true, "svn":{"repository":"/project/engsvn", "revision":"144827", "paths":["xdmp/branches/b5_0/src/Forest.cpp", "xdmp/branches/b5_0/src/StandManager.cpp", "xdmp/branches/b5_0/src/Forest.h"], "affectedBugs":[]}, "comment":"bug:20857"}, {"time":"2013-06-20T22:19:45.9483-07:00", "updatedBy":{"username":"cjl", "name":"Christopher Lindblad", "email":"cjl@cerisent.com"}, "change":{}, "files":[], "show":true, "svn":{"repository":"/project/engsvn", "revision":"144830", "paths":["xdmp/branches/b5_0/src/Forest.cpp"], "affectedBugs":[]}, "comment":"bug:20857"}, {"time":"2014-03-25T10:29:24.543692-07:00", "updatedBy":{"username":"svempati", "name":"Sundeep Vempati", "email":"sundeep.vempati@marklogic.com"}, "change":{}, "files":[], "show":true, "comment":"Blocked on this bug:\r\nBug 26355 -  Failover Stress: One of the forests attached to Master database is stuck in 'start closing' state and the forest ended up in Error State"}, {"time":"2014-03-27T09:28:51.165255-07:00", "updatedBy":{"username":"svempati", "name":"Sundeep Vempati", "email":"sundeep.vempati@marklogic.com"}, "change":{"status":{"from":"", "to":"Ship"}, "assignTo":{"from":{"username":"svempati", "name":"Sundeep Vempati", "email":"sundeep.vempati@marklogic.com"}, "to":{"username":"nobody", "name":"nobody nobody", "email":"nobody@marklogic.com"}}}, "files":[], "show":true, "comment":"Verified on MarkLogic-5.0-20140326"}], "updatedAt":"2014-03-27T09:28:51.165255-07:00", "fixedAt":"2013-06-20T13:39:01.94261-07:00", "fixedBy":{"username":"cjl", "name":"Christopher Lindblad", "email":"cjl@cerisent.com"}, "shippedAt":"2014-03-27T09:28:51.165255-07:00", "shippedBy":{"username":"svempati", "name":"Sundeep Vempati", "email":"sundeep.vempati@marklogic.com"}, "renderDescriptionAs":"normal"}